Running SLURM prolog script on pink52.cluster.local
===============================================================================
Job started on Wed Mar  5 16:06:23 GMT 2025
Job ID          : 7138942
Job name        : plm_c10_symm_02
WorkDir         : /mainfs/scratch/dk2g21/PLM
Command         : /mainfs/scratch/dk2g21/PLM/plm_ncd.slurm
Partition       : lyceum
Num hosts       : 1
Num cores       : 8
Num of tasks    : 1
Hosts allocated : pink52
Job Output Follows ...
===============================================================================
Wed Mar  5 16:06:24 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce GTX 1080 Ti     Off | 00000000:02:00.0 Off |                  N/A |
| 23%   33C    P8               9W / 250W |      0MiB / 11264MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce GTX 1080 Ti     Off | 00000000:03:00.0 Off |                  N/A |
| 23%   28C    P8               8W / 250W |      0MiB / 11264MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Starting main function...
Patching CIFAR-10 raw data...
Running in NCD Mode: Splitting CIFAR-10 into known and novel classes.
Dataset loaded successfully!
Generating noise labels...
[[0.8  0.05 0.05 0.05 0.05]
 [0.05 0.8  0.05 0.05 0.05]
 [0.05 0.05 0.8  0.05 0.05]
 [0.05 0.05 0.05 0.8  0.05]
 [0.05 0.05 0.05 0.05 0.8 ]]
0.79732
Generated noise_labels shape: 25000 (Expected: 25000)
----------------Labeling----------------
Size of ordinary_train_dataset: 25000
Size of noise_labels: 25000
Filtering training dataset for known classes in prenp.
Starting prenp training for candidate labeling...
Prenp Epoch 0 complete. Avg Loss = 1.0179
Prenp Epoch 1 complete. Avg Loss = 0.7029
Prenp Epoch 2 complete. Avg Loss = 0.5492
Prenp Epoch 3 complete. Avg Loss = 0.4611
Prenp Epoch 4 complete. Avg Loss = 0.3974
Prenp Epoch 5 complete. Avg Loss = 0.3592
Prenp Epoch 6 complete. Avg Loss = 0.3259
Prenp Epoch 7 complete. Avg Loss = 0.3047
Prenp Epoch 8 complete. Avg Loss = 0.2920
Prenp Epoch 9 complete. Avg Loss = 0.2676
Prenp Epoch 10 complete. Avg Loss = 0.2505
Prenp Epoch 11 complete. Avg Loss = 0.2408
Prenp Epoch 12 complete. Avg Loss = 0.2281
Prenp Epoch 13 complete. Avg Loss = 0.2166
Prenp Epoch 14 complete. Avg Loss = 0.2132
Prenp Epoch 15 complete. Avg Loss = 0.2177
Prenp Epoch 16 complete. Avg Loss = 0.2147
Prenp Epoch 17 complete. Avg Loss = 0.2009
Prenp Epoch 18 complete. Avg Loss = 0.1941
Prenp Epoch 19 complete. Avg Loss = 0.1901
Prenp Epoch 20 complete. Avg Loss = 0.1835
Prenp Epoch 21 complete. Avg Loss = 0.1827
Prenp Epoch 22 complete. Avg Loss = 0.1791
Prenp Epoch 23 complete. Avg Loss = 0.1865
Prenp Epoch 24 complete. Avg Loss = 0.1682
Prenp Epoch 25 complete. Avg Loss = 0.1831
Prenp Epoch 26 complete. Avg Loss = 0.1625
Prenp Epoch 27 complete. Avg Loss = 0.1765
Prenp Epoch 28 complete. Avg Loss = 0.1656
Prenp Epoch 29 complete. Avg Loss = 0.1633
Prenp Epoch 30 complete. Avg Loss = 0.1622
Prenp Epoch 31 complete. Avg Loss = 0.1742
Prenp Epoch 32 complete. Avg Loss = 0.1491
Prenp Epoch 33 complete. Avg Loss = 0.1731
Prenp Epoch 34 complete. Avg Loss = 0.1668
Prenp Epoch 35 complete. Avg Loss = 0.1685
Prenp Epoch 36 complete. Avg Loss = 0.1600
Prenp Epoch 37 complete. Avg Loss = 0.1558
Prenp Epoch 38 complete. Avg Loss = 0.1530
Prenp Epoch 39 complete. Avg Loss = 0.1763
Prenp Epoch 40 complete. Avg Loss = 0.1639
Prenp Epoch 41 complete. Avg Loss = 0.1598
Prenp Epoch 42 complete. Avg Loss = 0.1590
Prenp Epoch 43 complete. Avg Loss = 0.1480
Prenp Epoch 44 complete. Avg Loss = 0.1563
Prenp Epoch 45 complete. Avg Loss = 0.1612
Prenp Epoch 46 complete. Avg Loss = 0.1527
Prenp Epoch 47 complete. Avg Loss = 0.1604
Prenp Epoch 48 complete. Avg Loss = 0.1525
Prenp Epoch 49 complete. Avg Loss = 0.1499
Prenp Epoch 50 complete. Avg Loss = 0.1619
Prenp Epoch 51 complete. Avg Loss = 0.1548
Prenp Epoch 52 complete. Avg Loss = 0.1558
Prenp Epoch 53 complete. Avg Loss = 0.1524
Prenp Epoch 54 complete. Avg Loss = 0.1447
Prenp Epoch 55 complete. Avg Loss = 0.1634
Prenp Epoch 56 complete. Avg Loss = 0.1526
Prenp Epoch 57 complete. Avg Loss = 0.1604
Prenp Epoch 58 complete. Avg Loss = 0.1494
Prenp Epoch 59 complete. Avg Loss = 0.1596
Prenp Epoch 60 complete. Avg Loss = 0.1508
Prenp Epoch 61 complete. Avg Loss = 0.1509
Prenp Epoch 62 complete. Avg Loss = 0.1564
Prenp Epoch 63 complete. Avg Loss = 0.1496
Prenp Epoch 64 complete. Avg Loss = 0.1553
Prenp Epoch 65 complete. Avg Loss = 0.1468
Prenp Epoch 66 complete. Avg Loss = 0.1632
Prenp Epoch 67 complete. Avg Loss = 0.1402
Prenp Epoch 68 complete. Avg Loss = 0.1481
Prenp Epoch 69 complete. Avg Loss = 0.1589
Prenp Epoch 70 complete. Avg Loss = 0.1481
Prenp Epoch 71 complete. Avg Loss = 0.1471
Prenp Epoch 72 complete. Avg Loss = 0.1522
Prenp Epoch 73 complete. Avg Loss = 0.1572
Prenp Epoch 74 complete. Avg Loss = 0.1442
Prenp Epoch 75 complete. Avg Loss = 0.1428
Prenp Epoch 76 complete. Avg Loss = 0.1534
Prenp Epoch 77 complete. Avg Loss = 0.1601
Prenp Epoch 78 complete. Avg Loss = 0.1396
Prenp Epoch 79 complete. Avg Loss = 0.1487
Prenp Epoch 80 complete. Avg Loss = 0.1470
Prenp Epoch 81 complete. Avg Loss = 0.1446
Prenp Epoch 82 complete. Avg Loss = 0.1552
Prenp Epoch 83 complete. Avg Loss = 0.1548
Prenp Epoch 84 complete. Avg Loss = 0.1478
Prenp Epoch 85 complete. Avg Loss = 0.1449
Prenp Epoch 86 complete. Avg Loss = 0.1464
Prenp Epoch 87 complete. Avg Loss = 0.1569
Prenp Epoch 88 complete. Avg Loss = 0.1440
Prenp Epoch 89 complete. Avg Loss = 0.1517
Prenp Epoch 90 complete. Avg Loss = 0.1490
Prenp Epoch 91 complete. Avg Loss = 0.1510
Prenp Epoch 92 complete. Avg Loss = 0.1507
Prenp Epoch 93 complete. Avg Loss = 0.1428
Prenp Epoch 94 complete. Avg Loss = 0.1491
Prenp Epoch 95 complete. Avg Loss = 0.1466
Prenp Epoch 96 complete. Avg Loss = 0.1409
Prenp Epoch 97 complete. Avg Loss = 0.1473
Prenp Epoch 98 complete. Avg Loss = 0.1568
Prenp Epoch 99 complete. Avg Loss = 0.1438
Prenp training complete.
Candidate labels and pre-trained model saved.
multi_labels.npy exists. Loading...
Loaded train_candidate_labels shape: (25000, 5)
Number of fully zero rows in train_candidate_labels: 0
Unique values in train_candidate_labels: [0 1]
Number of zero rows: 0
raw_dataset.targets shape: (25000,)
Initializing model...
Model initialized!
Starting pre-training...
Epoch 0: Pre-training complete
Epoch 1: Pre-training complete
Epoch 2: Pre-training complete
Epoch 3: Pre-training complete
Epoch 4: Pre-training complete
Epoch 5: Pre-training complete
Epoch 6: Pre-training complete
Epoch 7: Pre-training complete
Epoch 8: Pre-training complete
Epoch 9: Pre-training complete
Epoch 10: Pre-training complete
Epoch 11: Pre-training complete
Epoch 12: Pre-training complete
Epoch 13: Pre-training complete
Epoch 14: Pre-training complete
Epoch 15: Pre-training complete
Epoch 16: Pre-training complete
Epoch 17: Pre-training complete
Epoch 18: Pre-training complete
Epoch 19: Pre-training complete
Epoch 20: Pre-training complete
Epoch 21: Pre-training complete
Epoch 22: Pre-training complete
Epoch 23: Pre-training complete
Epoch 24: Pre-training complete
Epoch 25: Pre-training complete
Epoch 26: Pre-training complete
Epoch 27: Pre-training complete
Epoch 28: Pre-training complete
Epoch 29: Pre-training complete
Epoch 30: Pre-training complete
Epoch 31: Pre-training complete
Epoch 32: Pre-training complete
Epoch 33: Pre-training complete
Epoch 34: Pre-training complete
Epoch 35: Pre-training complete
Epoch 36: Pre-training complete
Epoch 37: Pre-training complete
Epoch 38: Pre-training complete
Epoch 39: Pre-training complete
Final Test Accuracy (Known Classes): 0.67
Evaluating Novel Class Discovery on novel (test) dataset...
Extracting features for novel class clustering...
Applying K-Means clustering with 5 clusters...
Novel Discovery - NMI: 0.2831, ARI: 0.2338
==============================================================================
Running epilogue script on pink52.

Submit time  : 2025-03-05T16:06:23
Start time   : 2025-03-05T16:06:23
End time     : 2025-03-05T16:54:33
Elapsed time : 00:48:10 (Timelimit=08:00:00)

Job ID: 7138942
Cluster: i5
User/Group: dk2g21/fp
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 8
CPU Utilized: 00:58:25
CPU Efficiency: 15.16% of 06:25:20 core-walltime
Job Wall-clock time: 00:48:10
Memory Utilized: 14.13 GB
Memory Efficiency: 0.00% of 16.00 B

